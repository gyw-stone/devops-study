k8s的持续集成流程

一个目标：容器操作；两地三中心；四层服务发现；五种 Pod 共享资源；六个 CNI 常用插件；七层负载均衡；八种隔离维度；
九个网络模型原则；十类 IP 地址；百级产品线；千级物理机；万级容器；相如无亿，k8s 有亿：亿级日服务人次。

1、一个目标：容器操作
K8s是自动化容器操作的开源平台，包括：部署、调度和节点集群间扩展
具体的功能：
  自动化容器部署和复制
  实时弹性收缩容器规模
  容器编排成组，并提供容器间的负载均衡
  调度： 容器在哪个机器上运行

组成：
  kubectl：客户端命令行工具，作为整个系统的操作入口。
  kube-apiserver：以 REST API 服务形式提供接口，作为整个系统的控制入口。
  kube-controller-manager：执行整个系统的后台任务，包括节点状态状况、Pod 个数、Pods 和Service 的关联等。
  kube-scheduler：负责节点资源管理，接收来自 kube-apiserver 创建 Pods 任务，并分配到某个节点。
  etcd：负责节点间的服务发现和配置共享。
  kube-proxy：运行在每个计算节点上，负责 Pod 网络代理。定时从 etcd 获取到 service 信息来做相应的策略。
  kubelet：运行在每个计算节点上，作为 agent，接收分配该节点的 Pods 任务及管理容器，周期性获取容器状态，反馈给 kube-apiserver。
  DNS：一个可选的 DNS 服务，用于为每个 Service 对象创建 DNS 记录，这样所有的 Pod 就可以通过 DNS 访问服务了。

2、两地三中心
两地三中心包括： 本地生成中心、本地灾备中心、异地灾备中心
两地一中心要解决的一个重要问题就是数据一致性问题
k8s使用etcd组件作为一个高可用、强一致性的服务发现存储仓库。用于配置共享和服务发现
etcd是受到Zookeeper和doozer启发而催生的项目，拥有以下几个特点：
  简单：基于HTTP+JSON的API让你用curl命令就可以轻松使用
  安全：可选SSL客户认证机制
  快速：每个实例每秒支持一千次写操作
  可信：使用Raft算法充分实现了分布式

3、四层服务发现
k8s提供了两种方式进行服务发现：
  环境变量： 当创建一个Pod时，kubelet会在该Pod中注入集群内所有Service的相关环境变量。需要
注意的是，要想一个Pod中注入某个Service的环境变量，Service必须比Pod先创建，所以使用环境
变量这种方式进行服务发现不可用。基于TCP
DNS:
  可以通过cluster add-on的方式轻松的创建KubeDNS来对集群内的Service进行服务发现.基于UDP

4、Pod共享资源
Pod是k8s最基本的操作单元，包含一个或多个紧密相关的容器
一个Pod可以被一个容器化的环境看作应用层的“逻辑宿主机”；一个Pod中的多个容器应用通常是紧密耦合的
Pod在Node上被创建、启动或者销毁；每个Pod里运行着一个特殊的被称之为Volume挂在卷，因此他们之间
通信和数据交换更为高效。
同一个Pod的容器之间仅需通过localhost就能互相通信
一个Pod中的应用容器共享五种资源：
  PID命名空间：Pod中不同应用程序可以看到其它应用程序的进程ID
  网络命名空间：Pod中多个容器能访问同一个IP和端口范围
  IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信
  UTS命名空间：Pod中多个容器共享一个主机名
  Volumes ：Pod中各个容器可以访问在Pod级别定义的Volumes
Pod的生命周期通过Replication Controller来管理

5、六个CNI常用插件
CNI(Container Network interface) 容器网络接口是Linux容器网络配置的一组标准和库，用户
需要根据这些标准和库来开发自己的容器网络插件，CNI只关注解决网络连接和容器销毁时的资源释放，提供一套框架。
CNI可以支持大量不同的网络模式，并且容器实现

6、七层负载均衡
提供负载均衡就不得不先提服务器之间的通信
IDC(Internet Data Center) 也可称为数据中心、机房，用来放置服务器。IDC网络是服务器间通信的桥梁
负载均衡：
  二层负载均衡：基于 MAC 地址的二层负载均衡。
  三层负载均衡：基于 IP 地址的负载均衡。
  四层负载均衡：基于 IP+端口 的负载均衡。
  七层负载均衡：基于 URL 等应用层信息的负载均衡。
用Ingress解决NodePort端口暴露的缺陷

7、八种隔离维度
K8s集群调度这边需要对上面从上到下、从粗细度到细粒度的隔离做相应的调度策略

8、网络模型基本原则
每个Pod都拥有一个独立的ip地址，而且假定所有的pod都在一个直接连通的、扁平的网络空间中

k8s如何暴露服务?
  1、NodePort
将服务的类型设置程NodePort-每个集群节点都会在节点上打开一个端口，对于NodePort服务，每个集群节点
在节点本身上打开一个端口，并将在该端口上接收到的流量重定向到基础服务，该服务仅在内部集群IP和端口上
才可访问，但也可通过所有节点上的专用端口访问
缺点：Service过多，开启的端口会及其庞大，而且难以维护，生产环境不建议使用
2、LoadBalance
将服务的类型设置为LoadBanlance,NodePort类型的一种扩展，这使得服务可以通过一个专用的负载均衡器来访问。
负载均衡器将流量重定向到跨所有节点的节点端口，客户端通过负载均衡器的IP连接到服务
缺点：每一个用LoadBanlance暴露的服务都会有它自己的IP地址和端口，不能做到一个ip地址就可以访问所有服务
3、Ingress
创建一个Ingress资源，通过一个IP地址公开多个服务，相当于一个网关入口，和springcloud的网关zuul,gateway类似
Ingress资源基于HTTP虚拟主机或URL的转发规则
Ingress资源类型：
 单Service资源型Ingress
 基于URL路径进行流量转发
 基于主机名称的虚拟主机
 TLS类型的Ingress资源




































